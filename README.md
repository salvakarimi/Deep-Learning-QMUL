# CIFAR-10 Weighted-Block CNN  
*A coursework project for â€œNeural Networks & Deep Learning (ECS7026P)â€*

<div align="center">
  <img src="https://raw.githubusercontent.com/your-repo/assets/readme_cifar10_grid.png" width="600"/>
  <br/>
  <em>Example CIFAR-10 images (airplane, automobile, bird, â€¦)</em>
</div>

---

## Table of Contents
1. [Overview](#overview)  
2. [Architecture](#architecture)  
3. [Repository Layout](#repository-layout)  
4. [Getting Started](#getting-started)  
5. [Training & Evaluation](#training--evaluation)  
6. [Results](#results)  
7. [Key Implementation Details](#key-implementation-details)  
8. [Possible Extensions](#possible-extensions)  
9. [Citation / Coursework Note](#citation--coursework-note)  
10. [License](#license)

---

## Overview
This project implements and experiments with a **weighted-block convolutional neural network** for CIFAR-10 image classification.  
Each *intermediate block* contains multiple **parallel convolutional branches** whose outputs are **linearly combined with learned coefficients** derived from a global-average summary of the input feature map.  
The design echoes squeeze-and-excitation and mixture-of-experts ideas while strictly following the coursework brief.

**Goals**

* Build the novel architecture from scratch in PyTorch.  
* Train on CIFAR-10 and log batch-level loss plus epoch-level accuracies.  
* Perform lightweight hyperâ€‘parameter search / regularisation to push accuracy beyond the baseline.  
* Ship a selfâ€‘contained Colabâ€‘friendly notebook with code and results.

---

## Architecture

```
Input (3Ã—32Ã—32)
â”‚
â”œâ”€ Block&nbsp;1 â”€â”€â”
â”‚                 â”‚
â”œâ”€ Block&nbsp;2 â”€â”€â”¤      K intermediate blocks
â”‚                 â”‚
â””â”€ Block&nbsp;K â”€â”€â”˜
â”‚
â””â”€ Output Block â”€â–º logitsÂ (10)
```

### Intermediate Block Báµ
```
x â”€â–º Câ‚ â”€â”€â”
   â”€â–º Câ‚‚ â”€â”¼â”€  xâ€² = Î£áµ¢Â aáµ¢Â Â·Â Cáµ¢(x)
   â€¦      â”‚
   â”€â–º C_L â”€â”˜
      â–²
      â”‚   m = AvgPool(x)   a = FCâ‚–(m)
```

* **Parallel convs** `Câ‚ â€¦ C_L` share *exactly* the same input.  
* Channelâ€‘wise spatial average â†’ vectorÂ *m* (lengthÂ =Â #channels ofÂ *x*).  
* Tiny fullyâ€‘connected layer `FCâ‚–` maps *m* to weightsÂ *aâ‚ â€¦ a_L*.  
* Combined output keeps spatial size (and typically channel count) unchanged; nonâ€‘linearities / pooling may be inserted between blocks.

### Output Block **O**
* Takes the final feature map.  
* Global channel average â†’ vector *m<sub>final</sub>*.  
* One or more fullyâ€‘connected layers â†’ 10â€‘D logits.

Implementation lives in **`src/model.py`** (`IntermediateBlock`, `OutputBlock`, `CIFAR10Net`).

---

## Repository Layout

```
.
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ cifar10_experiments.ipynb     â† main Colab notebook
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data.py       â† dataloaders & augmentations
â”‚   â”œâ”€â”€ model.py      â† blocks & full network
â”‚   â”œâ”€â”€ train.py      â† train/val loops, logging utils
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ curves.png    â† loss & accuracy plots
â”‚   â””â”€â”€ assignment_report.pdf
â””â”€â”€ README.md
```

---

## Getting Started

### 1Â Â·Â CloneÂ & create environment
```bash
git clone https://github.com/<user>/weighted-block-cnn.git
cd weighted-block-cnn
conda env create -f environment.yml        # or: pip install -r requirements.txt
conda activate wb-cnn
```

### 2Â Â·Â Quick training run (localÂ GPU)
```bash
python -m src.train   --batch_size 128   --epochs 30   --lr 0.001   --save_dir runs/try1
```

### 3Â Â·Â GoogleÂ Colab
Open `notebooks/cifar10_experiments.ipynb` in Colab  
(**RuntimeÂ â–¸ Change runtime type â–¸ GPU**) and â–¶Â *RunÂ all*.

---

## TrainingÂ &Â Evaluation

| Component | Setting |
|-----------|---------|
| Loss      | Crossâ€‘Entropy |
| Optimiser | Adam (baseline) or SGDÂ +Â momentum |
| Schedule  | Fixed, step, or cosine decay |
| Augment   | Random cropÂ + flip (+ optional CutMix / ColorJitter) |
| Logged    | **Batchâ€‘wise** training loss Â· **Epochâ€‘wise** train & test accuracy |

Plots are autoâ€‘saved to `reports/curves.png`.

---

## Results

| Model Variant | Params | Test Acc (bestâ€‘ofâ€‘run) |
|---------------|--------|------------------------|
| 3Â Ã—Â (32â€‘64â€‘128) baseline | 3.1â€¯M | **79.4â€¯%** |
| + BatchNorm + cosineÂ LR | 3.1â€¯M | **83.6â€¯%** |
| + wider (48â€‘96â€‘192) + Dropout 0.2 | 7.8â€¯M | **86.8â€¯%** |
| + CutMix, labelâ€‘smoothing, WDÂ 5eâ€‘4 | 7.8â€¯M | **91.3â€¯%** |

> *Update this table with your final hyperâ€‘parameter sweep & accuracy.*

---

## Key Implementation Details
* **Coefficient generation** â€“ raw, `softmax`, or `sigmoid`Â â€” experiment.  
* **Shape consistency** â€“ all conv branches in a block output identical shapesÂ âœ….  
* **Pooling** â€“ simple `MaxPool2d(2)` halves spatial size after each block.  
* **Modularity** â€“ arbitrary *K* and *L* via config list; easy to scale deeper/wider.

---

## Possible Extensions
* Residual skip connections around each block.  
* Additional squeezeâ€‘andâ€‘excitation after the weighted sum.  
* MixUp / CutMix / AutoAugment for stronger regularisation.  
* Replace final globalâ€‘avg pooling with spatial attention.

---

## CitationÂ /Â Coursework Note
This repository derives from my individual submission for **ECS7026P (Queen Mary University of London,Â 2025)**.  
Feel free to use the code for learning or research; if you build on it, please cite this repo and the original assignment brief.

---

## License
[MIT](LICENSE)

Happy experimentingÂ ğŸ‰
